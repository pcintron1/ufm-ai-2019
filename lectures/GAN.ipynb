{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Un GAN es como una batalla entre dos adversarios\n",
    "    * Un generador\n",
    "    * Un discriminador\n",
    "* El generador intenta convertir ruido aleatorio en observaciones que parecen como si han sido muestreadas del dataset original\n",
    "* El discriminador intenta predecir si una observacion viene del dataset original o si es una creada por el generador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Al inicio del proceso el generador va a crear imagenes ruidosas y las predicciones del discriminador van a ser aleatorias\n",
    "* La clave de los GANs yace en como alternar el entrenamiento de las dos redes:\n",
    "    * el generador debe volverse mejor en enganiar al discriminador\n",
    "    * el discriminador debe adaptarse para mantener su habilidad de identificar que observaciones son falsas\n",
    "    * Esto causa que el generador encuentra nuevas formas de enganiar al discriminador y el ciclo continua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Discriminador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La meta del discriminador es predecir si una imagen es real o falsa\n",
    "    * Esto es un problema de clasificacion de imagenes supervisada.\n",
    "    * Por esta razon podemos usar la misma arquitectura de red que vimos la clase anterior: un stack de convolutional layers seguidas por un fully connected output layer\n",
    "* En el paper original del GAN, se usaron fully connected layers en vez de convolutional layers.\n",
    "    * Sin embargo, desde entonces, se ha comprobado que las convolutional layers proveen mejor rendimiento para el discriminador\n",
    "* Puede ser que vean un tipo de GAN llamado DCGAN (deep convolutional generative adversarial network) en la literatura.\n",
    "    * Ahora todas las arquitecturas de GANs contienen convolutional layers, entonces el DC esta implicito.\n",
    "* Tambien es comun ver batch normalization layers en el discriminador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Definir el input al discriminador (la imagen)\n",
    "2. Apilar convolutional layers\n",
    "3. Aplanar la ultima convolutional layer a un vector\n",
    "4. Capa lineal de una unidad, con una funcion de activacion sigmoide que transforma el output a un rango [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Generador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El input al generador es un vector $z$, usualmente muestreado de una distribucion normal multivariable.\n",
    "* El output es una imagen del mismo tamanio que una imagen en el training set original.\n",
    "* Esta descripcion es parecida al decoder en el VAE.\n",
    "    * De hecho, el generador de un GAN cumple el mismo proposito que el decoder de un VAE\n",
    "    * Convertir un vector en el espacio latente -> imagen\n",
    "* El concepto de mapear de un espacio latente de regreso a al dominio original es muy comun en modelado generativo.\n",
    "    * Nos provee la habilidad de manipular vectores en el espacio latente para cambiar high-level features de imagenes en el dominio original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En el decoder del VAE que vimos, duplicamos el ancho y la altura del tensor en cada layer usando `ConvTranspose2d` layers.\n",
    "    * Esto insertaba ceros entre pixeles antes de realizar las operaciones del convolution\n",
    "* El objetivo de esto es transformar el input de regreso al dominio de la imagen original.\n",
    "* Como vimos en el VAE los `ConvTranspose2d` pueden generar artefactos\n",
    "    * pequenios patrones de ajedrez en las imagenes de output\n",
    "    * eso tiene un impacto en la calidad de la imagen generada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Como hemos visto, la arquitectura del generado y el discriminador en un GAN es bastante simple\n",
    "* La clave es entender el proceso de entrenamiento\n",
    "\n",
    "* Podemos entrenar el discriminador creando un training set donde algunas imagenes son seleccionadas de forma aleatoria\n",
    "    * observaciones _reales_ del training set\n",
    "    * outputs del generador\n",
    "    * La respuesta seria 1 para imagenes reales y 0 para imagenes generadas\n",
    "\n",
    "* Entrenar el generador es mas dificil:\n",
    "    * No tenemos un training set que nos indique la imagen _verdadera_ a la que un punto en particular en el espacio latente debe ser mapeada\n",
    "    * En vez, lo que queremos es que la imagen generada enganie al discriminador\n",
    "    * Cuando la imagen ingrese al discriminador el output deberia ser cercano a 1\n",
    "\n",
    "* Por tanto, para entrenar el generador, primero necesitamos conectarlo al discriminador para crear un modelo que podamos entrenar.\n",
    "* Especificamente, le alimentamos el output del generador al discriminador\n",
    "    * el output de este modelo combinado es la probabilidad de que la imagen generada sea _real_ de acuerdo al discriminador\n",
    "* Podemos entrenar este modelo combinado creando batches de entrenamiento que consisten de:\n",
    "    * vectores de 100-dimensiones generadas de forma aleatoria\n",
    "    * un label 1, ya que queremos entrenar al generador a producir imagenes que el discriminador piensa que son reales.\n",
    "\n",
    "* El loss function entonces es solo el binary cross-entropy loss entre el output del discriminador y el vector de labels de 1s.\n",
    "\n",
    "* Es importante que congelemos los pesos del discriminador mientras estamos entrenando el modelo combinado\n",
    "    * De esta forma solo los pesos del generador se actualizan.\n",
    "* Si no congelamos los pesos del discriminador, el discriminador se va a ajustar para que sea mas probable que prediga que las imagenes generadas son reales. Esto no es lo que queremos.\n",
    "* Queremos que las imagenes generadas sean predecidas para tener un valor cercano a 1 (real) porque el generador es fuerte y no porque el discriminador es debil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafios del GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aunque los GANs fueron un gran avance para el modelado generativo tambien son notoriamente dificiles de entrenar.\n",
    "* A continuacion vamos a ver los problemas mas comunes\n",
    "* Luego algunos ajustes al framework de un GAN para remediar los problemas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oscillating Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El loss del discriminador y un generador empiezan oscilar bastante, en vez de exhibir estabilidad a largo plazo.\n",
    "* Es normal que hayan oscilaciones entre batches, pero a largo plazo deberiamos buscar un loss que se estabiliza a largo plazo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode Collapse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ocurre cuando el generador encuentra pequenios numeros de muestras que enganian al discriminador\n",
    "    * deja de producir ejemplos afuera de este conjunto limitado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uninformative Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dado que el modelo es creado para minimizar el loss function, es natural pensar que mientras mas pequenia sea el loss del generador, mejor la calidad de imagenes producidas\n",
    "* Sin embargo, como el generador solo es calificado contra el discriminador actual y el discriminador esta constantemente mejorando, no podemos comparar el loss function evaluado en diferentes puntos a lo largo del proceso de entrenamiento.\n",
    "* El loss del generador puede estar incrementando a traves del tiempo, aunque la calidad de imagenes mejore.\n",
    "* Esta falta de correlacion entre el loss del generador y la calidad de imagenes hace dificil monitorear el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soluciones para los problemas del GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En anios recientes, avances clave han mejorado drasticamente la estabilidad de los GANs y disminuido la frequencia de los problemas que vimos.\n",
    "* Vamos a explorar dos de estos avances\n",
    "    * Wasserstein GAN (WGAN)\n",
    "    * Wassertein GAN-Gradient Penalty (WGAN-GP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wasserstein GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uno de los primeros grandes avances para estabilizar el entrenamiento de GANs.\n",
    "* Con algunos cambios, los autores demostraron como entrenar GANs que tienen las siguientes propiedades:\n",
    "    * Una metrica de loss con significado que se correlaciona con la convergencia del generador y la calidad de las muestras.\n",
    "    * Mejora en la estabilidad del proceso de optimizacion\n",
    "    \n",
    "* Especificamente este paper introduce una nueva loss function para el discriminador y el generador.\n",
    "* Usando esta loss function en vez de binarry cross entropy resulta en una convergencia mas estable del GAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wasserstein Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ -\\frac{1}{n}\\sum_{i=1}^{n}(y_i p_i) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein(y_true, y_pred):\n",
    "    return -np.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lipschitz Constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Como el wasserstein loss ya no restringe los outputs al rango $[0,1]$ si no a $[-\\infty, \\infty]$, el loss puede ser bastante grande.\n",
    "* Los autores del loss demostraron que para que el Wasserstein loss funcione, hay que agregar restricciones adicionales.\n",
    "* Especificamente se requiere que el critico (discriminador) sea _1-Lipschitz continuous function_. \n",
    "\n",
    "* El critic es una funcion D que convierte una imagen en una prediccion.\n",
    "* Decimos que esta funcion es 1-Lipschitz si satisface la siguiente desigualdad para dos imagenes input, $x_1$ y $x_2$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\lvert D(x_1) - D(x_2)\\rvert}{\\lvert x_1 - x_2 \\rvert} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aqui, el denominador es la diferencia absoluta promedio entre dos imagenes (a nivel pixel)\n",
    "* El numerador es la diferencia absoluta entre las predicciones del critic.\n",
    "* En esencia, requerimos un limite sobre la razon de cambio en la que las predicciones del critic pueden cambiar entre dos imagenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En el WGAN paper, los autores demuestran que es posible hacer cumplir el Lipschitz constraint haciendo clipping de los pesos del critic para que se encuentren en un rango pequenio, $[-0.01, 0.01]$ despues de cada batch en entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()        \n",
    "loss, hidden = model(data, hidden, targets)\n",
    "loss.backward()\n",
    "\n",
    "# Aqui sucede el gradient clipping\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
