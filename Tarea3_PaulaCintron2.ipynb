{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 3\n",
    "\n",
    "- Paula Cintron 20160090\n",
    "- Lunes 11 de agosto 2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ejercicios\n",
    "\n",
    "1. Redefinan el model a w2 * t_u ** 2 + w1 * t_u + b\n",
    "2. Que partes del training loop necesitaron cambiar para acomodar el nuevo modelo?\n",
    "3. Que partes se mantuvieron iguales?\n",
    "4. El loss resultante es mas alto o bajo despues de entrenamiento?\n",
    "5. El resultado es mejor o peor?\n",
    "\n",
    "\n",
    "Se necesitaron agregar dimensiones para que el nuevo modelo encajara a los dos pesos agregados. Se mantuvo igual la arquitectura original del modelo. Solo se le agregaron variables y se reestructuró el modelo a un modelo multivariable. El loss resultó ser mas bajo. El resultado es mejor dado que al entrenar el modelo se adapta a los parámetros dados (menor learning rate y no epochs). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Redefinan el model a w2 * t_u ** 2 + w1 * t_u + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para empezar, quiero repasar el código del modelo hecho en clase para luego construir sobre él y modificarlo.\n",
    "Este es el modelo del ejercicio hecho en clase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definiendo las variables\n",
    "\n",
    "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0] # Temperatura en grados celsios\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4] # Unidades desconocidas\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definiendo el modelo inicial\n",
    "\n",
    "def model(t_u, w, b):\n",
    "    return w * t_u + b\n",
    "\n",
    "\n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,\n",
       "        48.4000, 60.4000, 68.4000])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definiendo los parámetros\n",
    "w = torch.ones(1)\n",
    "b = torch.zeros(1)\n",
    "\n",
    "t_p = model(t_u, w, b)\n",
    "t_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1763.8846)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(t_p, t_c)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redefiniendo el parámetro w \n",
    "# w = gradient descent \n",
    "# redefiniendo w1 \n",
    "\n",
    "#Estos son el w y b dados del ejercicio hecho en clase \n",
    "delta = 0.1\n",
    "\n",
    "loss_rate_of_change_w = (loss_fn(model(t_u, w + delta, b), t_c) -\n",
    "                        loss_fn(model(t_u, w - delta, b), t_c)) / (2.0 * delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "w = w - learning_rate * loss_rate_of_change_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rate_of_change_b = (loss_fn(model(t_u, w, b + delta), t_c) -\n",
    "                        loss_fn(model(t_u, w, b - delta), t_c) / (2.0 * delta))\n",
    "\n",
    "b = b - learning_rate * loss_rate_of_change_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Versión analítica \n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c) ** 2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dloss_fn(t_p, t_c):\n",
    "    dsq_diffs = 2 * (t_p - t_c)\n",
    "    return dsq_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w, b):\n",
    "    return w * t_u + b\n",
    "\n",
    "\n",
    "def dmodel_dw(t_u, w, b):\n",
    "    return t_u\n",
    "\n",
    "\n",
    "def dmodel_db(t_u, w, b):\n",
    "    return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grad_fn(t_u, t_c, t_p, w, b):\n",
    "    dloss_dw = dloss_fn(t_p, t_c) * dmodel_dw(t_u, w, b)\n",
    "    dloss_db = dloss_fn(t_p, t_c) * dmodel_db(t_u, w, b)\n",
    "    return torch.stack([dloss_dw.mean(), dloss_db.mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armando el training loop \n",
    "def training_loop(model, n_epochs, learning_rate, params, t_u, t_c, print_params=True):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        w, b = params\n",
    "        \n",
    "        t_p = model(t_u, w, b) # Forward pass\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        grad = grad_fn(t_u, t_c, t_p, w, b) # Backward pass\n",
    "        \n",
    "        params = params - learning_rate * grad\n",
    "        \n",
    "        if epoch % 10 == 0 or epoch == 1:\n",
    "            print(f\"Epoch {epoch}, Loss {loss}\")\n",
    "            if print_params:\n",
    "                print(f\"\\tParams: {params}\")\n",
    "                print(f\"\\tGrad: {grad}\")\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1763.8846435546875\n",
      "\tParams: tensor([-44.1730,  -0.8260])\n",
      "\tGrad: tensor([4517.2964,   82.6000])\n",
      "Epoch 10, Loss 9.090107547845813e+34\n",
      "\tParams: tensor([3.2144e+17, 5.6621e+15])\n",
      "\tGrad: tensor([-3.2700e+19, -5.7600e+17])\n",
      "Epoch 20, Loss inf\n",
      "\tParams: tensor([1.3457e+35, 2.3704e+33])\n",
      "\tGrad: tensor([-1.3690e+37, -2.4114e+35])\n",
      "Epoch 30, Loss nan\n",
      "\tParams: tensor([nan, nan])\n",
      "\tGrad: tensor([nan, nan])\n",
      "Epoch 40, Loss nan\n",
      "\tParams: tensor([nan, nan])\n",
      "\tGrad: tensor([nan, nan])\n",
      "Epoch 50, Loss nan\n",
      "\tParams: tensor([nan, nan])\n",
      "\tGrad: tensor([nan, nan])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Corriendo el traning loop\n",
    "training_loop(model,\n",
    "              n_epochs = 50,\n",
    "              learning_rate= 1e-2,\n",
    "              params = torch.tensor([1.0, 0.0]),\n",
    "              t_u = t_u,\n",
    "              t_c = t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Redefinan el model a w2 * t_u ** 2 + w1 * t_u + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a armar el modelo usando w1 y w2 como dos pesos individuales diferentes. Sin embargo, ambos seran matrices de 1 pero con diferentes pesos de delta.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definiendo las variables\n",
    "\n",
    "t_c1 = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0] # Temperatura en grados celsios\n",
    "t_u1 = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4] # Unidades desconocidas\n",
    "t_c1 = torch.tensor(t_c1)\n",
    "t_u1 = torch.tensor(t_u1)\n",
    "# Normalizando la data\n",
    "t_u1 = 0.1 * t_u1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16.3149, 36.8381, 39.6924, 75.2661, 37.3269, 28.8021, 14.8821,  6.9324,\n",
       "        28.2656, 42.5216, 53.6256])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_u1**2 + t_u1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Definiendo el modelo 2\n",
    "\n",
    "def model2(t_u1, w1, w2, b):\n",
    "    return w2 * t_u1 ** 2 + w1 * t_u1 + b\n",
    "\n",
    "\n",
    "def loss_fn(t_p1, t_c1):\n",
    "    squared_diffs = (t_p1 - t_c1)**2\n",
    "    return squared_diffs.mean()\n",
    "\n",
    "#def model3(t_u1,w3,b):\n",
    "   # return w3 * t_u1 **2 + w3 * t_u1 +b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16.3149, 36.8381, 39.6924, 75.2661, 37.3269, 28.8021, 14.8821,  6.9324,\n",
       "        28.2656, 42.5216, 53.6256])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definiendo los parámetros\n",
    "#Definiendo los parámetros\n",
    "w1 = torch.ones(1)\n",
    "w2 = torch.ones(1)\n",
    "b = torch.zeros(1)\n",
    "#w3 =torch.ones([2,1])\n",
    "\n",
    "t_p1 = model2(t_u1, w1, w2, b)\n",
    "t_p1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_p2 = model3(t_u1,w3,b)\n",
    "#t_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(675.7943)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ver el resultado Loss de este nuevo modelo.\n",
    "loss = loss_fn(t_p1, t_c1)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armando el entrenamiento del nuevo modelo\n",
    "\n",
    "#Estos son el w y b nuevos\n",
    "delta2 = 0.1\n",
    "\n",
    "loss_rate_of_change_w1 = (loss_fn(model2(t_u1, w1 + delta2,w2, b), t_c1) -\n",
    "                        loss_fn(model2(t_u1, w1 - delta2,w2, b), t_c1)) / (2.0 * delta2)\n",
    "delta3 = 0.2\n",
    "\n",
    "loss_rate_of_change_w2 = (loss_fn(model2(t_u1, w1 ,w2 + delta3,b), t_c1) -\n",
    "                        loss_fn(model2(t_u1, w1,w2 - delta3, b ), t_c1)) / (2.0 * delta3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definiendo w1 y w2 \n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "w1 = w1 - learning_rate * loss_rate_of_change_w1\n",
    "\n",
    "\n",
    "w2 = w2 - learning_rate * loss_rate_of_change_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9720])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8260])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta1= 0.1\n",
    "loss_rate_of_change_b = (loss_fn(model2(t_u1, w1,w2,  b + delta1), t_c1) -\n",
    "                        loss_fn(model2(t_u1, w1, w2, b - delta1), t_c1) / (2.0 * delta))\n",
    "\n",
    "b = b - learning_rate * loss_rate_of_change_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1584])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parte analítica\n",
    "def loss_fn(t_p1, t_c1):\n",
    "    squared_diffs = (t_p1 - t_c1) ** 2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dloss_fn(t_p1, t_c1):\n",
    "    dsq_diffs = 2 * (t_p1 - t_c1)\n",
    "    return dsq_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(t_u1, w1, w2, b):\n",
    "    return w2*(t_u1**2) + (w1*t_u1) + b\n",
    "\n",
    "\n",
    "def dmodel_dw(t_u1, w1, w2, b):\n",
    "    return t_u\n",
    "\n",
    "\n",
    "def dmodel_db(t_u1, w1, w2, b):\n",
    "    return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grad_fn(t_u1, t_c1, t_p1, w1, w2, b):\n",
    "    dloss_dw = dloss_fn(t_p1, t_c1) * dmodel_dw(t_u1, w1, w2, b)\n",
    "    dloss_db = dloss_fn(t_p1, t_c1) * dmodel_db(t_u1, w1, w2, b)\n",
    "    return torch.stack([dloss_dw.mean(), dloss_dw.mean(),dloss_db.mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer cambio: esta funcion ahora tiene que retornar un tensor con 3 argumentos para que se pueda hacer la multiplicación mas adelante. Dado que se ingresa  t_u1 dos veces, retornaremos esa perdida dos veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armando el training loop \n",
    "def training_loop(model2, n_epochs, learning_rate, params, t_u1, t_c1, print_params=True):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        w1, w2, b = params\n",
    "        \n",
    "        t_p1 = model2(t_u1, w1, w2, b) # Forward pass\n",
    "        loss = loss_fn(t_p1, t_c1)\n",
    "        grad = grad_fn(t_u1, t_c1, t_p1, w1, w2, b) # Backward pass\n",
    "        \n",
    "        params = params - learning_rate * grad\n",
    "        print(params)\n",
    "        \n",
    "        if epoch % 10 == 0 or epoch == 1:\n",
    "            print(f\"Epoch {epoch}, Loss {loss}\")\n",
    "            if print_params:\n",
    "                print(f\"\\tParams: {params}\")\n",
    "                print(f\"\\tGrad: {grad}\")\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo cambio: se le agrega un nuevo parametro al tensor de params, para poder realizar la multiplicacion con el cambio que se hizo en grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0067, 0.0067, 1.0001])\n",
      "Epoch 1, Loss 70.72434997558594\n",
      "\tParams: tensor([1.0067, 0.0067, 1.0001])\n",
      "\tGrad: tensor([-672.5403, -672.5403,   -8.6400])\n",
      "tensor([1.0132, 0.0132, 1.0002])\n",
      "tensor([1.0193, 0.0193, 1.0002])\n",
      "tensor([1.0253, 0.0253, 1.0003])\n",
      "tensor([1.0309, 0.0309, 1.0004])\n",
      "tensor([1.0364, 0.0364, 1.0005])\n",
      "tensor([1.0416, 0.0416, 1.0005])\n",
      "tensor([1.0466, 0.0466, 1.0006])\n",
      "tensor([1.0514, 0.0514, 1.0006])\n",
      "tensor([1.0560, 0.0560, 1.0007])\n",
      "Epoch 10, Loss 46.141624450683594\n",
      "\tParams: tensor([1.0560, 0.0560, 1.0007])\n",
      "\tGrad: tensor([-458.7160, -458.7160,   -5.0851])\n",
      "tensor([1.0604, 0.0604, 1.0007])\n",
      "tensor([1.0646, 0.0646, 1.0008])\n",
      "tensor([1.0686, 0.0686, 1.0008])\n",
      "tensor([1.0725, 0.0725, 1.0008])\n",
      "tensor([1.0762, 0.0762, 1.0009])\n",
      "tensor([1.0797, 0.0797, 1.0009])\n",
      "tensor([1.0831, 0.0831, 1.0010])\n",
      "tensor([1.0864, 0.0864, 1.0010])\n",
      "tensor([1.0895, 0.0895, 1.0010])\n",
      "tensor([1.0925, 0.0925, 1.0010])\n",
      "Epoch 20, Loss 33.11180114746094\n",
      "\tParams: tensor([1.0925, 0.0925, 1.0010])\n",
      "\tGrad: tensor([-299.8586, -299.8586,   -2.4441])\n",
      "tensor([1.0954, 0.0954, 1.0011])\n",
      "tensor([1.0982, 0.0982, 1.0011])\n",
      "tensor([1.1008, 0.1008, 1.0011])\n",
      "tensor([1.1033, 0.1033, 1.0011])\n",
      "tensor([1.1058, 0.1058, 1.0011])\n",
      "tensor([1.1081, 0.1081, 1.0011])\n",
      "tensor([1.1103, 0.1103, 1.0011])\n",
      "tensor([1.1124, 0.1124, 1.0012])\n",
      "tensor([1.1145, 0.1145, 1.0012])\n",
      "tensor([1.1164, 0.1164, 1.0012])\n",
      "Epoch 30, Loss 27.006025314331055\n",
      "\tParams: tensor([1.1164, 0.1164, 1.0012])\n",
      "\tGrad: tensor([-196.0224, -196.0224,   -0.7178])\n",
      "tensor([1.1183, 0.1183, 1.0012])\n",
      "tensor([1.1201, 0.1201, 1.0012])\n",
      "tensor([1.1219, 0.1219, 1.0012])\n",
      "tensor([1.1235, 0.1235, 1.0012])\n",
      "tensor([1.1251, 0.1251, 1.0012])\n",
      "tensor([1.1266, 0.1266, 1.0012])\n",
      "tensor([1.1281, 0.1281, 1.0012])\n",
      "tensor([1.1295, 0.1295, 1.0012])\n",
      "tensor([1.1308, 0.1308, 1.0012])\n",
      "tensor([1.1321, 0.1321, 1.0012])\n",
      "Epoch 40, Loss 24.044971466064453\n",
      "\tParams: tensor([1.1321, 0.1321, 1.0012])\n",
      "\tGrad: tensor([-128.1505, -128.1505,    0.4105])\n",
      "tensor([1.1333, 0.1333, 1.0012])\n",
      "tensor([1.1345, 0.1345, 1.0012])\n",
      "tensor([1.1356, 0.1356, 1.0012])\n",
      "tensor([1.1367, 0.1367, 1.0012])\n",
      "tensor([1.1377, 0.1377, 1.0011])\n",
      "tensor([1.1387, 0.1387, 1.0011])\n",
      "tensor([1.1397, 0.1397, 1.0011])\n",
      "tensor([1.1406, 0.1406, 1.0011])\n",
      "tensor([1.1415, 0.1415, 1.0011])\n",
      "tensor([1.1423, 0.1423, 1.0011])\n",
      "Epoch 50, Loss 22.549335479736328\n",
      "\tParams: tensor([1.1423, 0.1423, 1.0011])\n",
      "\tGrad: tensor([-83.7866, -83.7866,   1.1480])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.1423, 0.1423, 1.0011])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Corriendo el traning loop\n",
    "#learning rate lo volví más pequeño que el original para que aprenda en gradientes mas pequeños\n",
    "#Se normalizó la data previo a correr el modelo\n",
    "training_loop(model2,\n",
    "              n_epochs = 50,\n",
    "              learning_rate= 1e-5,\n",
    "              params = torch.tensor([1.0,0.0,1]),\n",
    "              t_u1 = t_u1,\n",
    "              t_c1 = t_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-175-6ae936388114>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                        \u001b[0mt_u1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_u1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                        \u001b[0mt_c1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_c1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                        print_params=False)\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-172-3fd114958764>\u001b[0m in \u001b[0;36mtraining_loop\u001b[1;34m(model2, n_epochs, learning_rate, params, t_u1, t_c1, print_params)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_u1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_c1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mt_p1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_u1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "#params = training_loop(model2,\n",
    "                       n_epochs = 5000,\n",
    "                       learning_rate= 1e-4,\n",
    "                       params = torch.tensor([1.0, 0.0]),\n",
    "                       t_u1 = t_u1,\n",
    "                       t_c1 = t_c1,\n",
    "                       print_params=False)\n",
    "\n",
    "#params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
